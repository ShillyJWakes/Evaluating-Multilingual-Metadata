{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "sns.set_context('paper')\n",
    "data_dir = Path('../data')\n",
    "input_dir = data_dir / 'input'\n",
    "output_dir = data_dir / 'output'\n",
    "figure_dir = Path(\"../figures\")\n",
    "\n",
    "df = pd.read_parquet(output_dir / '04_language_detection.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness and Quality issues\n",
    "\n",
    "Dividing issues between 'Completeness' and 'Quality' and getting the sum of issues for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness = ['Author Missing', 'Article Language Missing', 'Journal Language Missing',\n",
    "                'Abstract Missing', 'Article Title Missing', 'Journal Title Missing',\n",
    "                'Affiliation Missing']\n",
    "quality = ['Institutions as Authors', 'Author Use of Honorific', 'Author Name in All Caps',\n",
    "           'Multilingual Abstract','Abstract Language Match', 'Non-ASCII Characters',\n",
    "           'Article-Journal Language Match', 'Title Language Match']\n",
    "df['Completeness Errors'] = df[completeness].sum(axis=1)\n",
    "df['Quality Errors'] = df[quality].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming\n",
    "\n",
    "Renaming the columns relevant to the visualizations for cleaner appearance in viz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['coral', 'thistle', 'skyblue', 'lightslategray']\n",
    "df2 = df.rename({'lang_type': 'Language Type'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness Issues\n",
    "\n",
    "**Figure 2**\n",
    "\n",
    "Viz for showing completeness issues, Grouped bar chart for seeing differences between language types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "comp_df = df2[['Language Type', 'Author Missing', 'Affiliation Missing', 'Abstract Missing',\n",
    "               'Article Language Missing', 'Journal Language Missing']]\n",
    "issue_columns = ['Author Missing', 'Affiliation Missing', 'Abstract Missing',\n",
    "               'Journal Language Missing', 'Article Language Missing']\n",
    "comp_df.fillna({'Affiliation Missing': 0, 'Language Type': 'Uncategorized'}, inplace=True)\n",
    "grouped = comp_df.groupby('Language Type')[issue_columns].mean(numeric_only=True).reset_index()\n",
    "melted = grouped.melt(id_vars='Language Type', var_name='issue', value_name='prevalence')\n",
    "melted['prevalence'] = melted.prevalence.map(lambda x: x * 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x='issue', y='prevalence', hue='Language Type', data=melted, palette=['thistle', 'coral', 'skyblue', 'silver'],\n",
    "            hue_order=['Monolingual English', 'Monolingual Non-English', 'Multilingual', 'Uncategorized'], ax=ax)\n",
    "\n",
    "# Add labels to the bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, size=8, fmt='%.1f')\n",
    "\n",
    "plt.xlabel('Issue', labelpad=12.5)\n",
    "plt.ylabel('Prevalence')\n",
    "plt.xticks(rotation=20)\n",
    "ax.legend(title='Language Type', bbox_to_anchor=(0, 1), loc='upper left', frameon=False)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(figure_dir / 'comp_lang_type.png', format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "A viz similar to above, but pertaining to the quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2.rename({'Title Language Match' : 'Title Language Mismatch'\n",
    " #                },\n",
    "  #                axis=1)\n",
    "\n",
    "qual_df = df2[['Language Type', 'Author Initials',\n",
    "               'Institutions as Authors',\n",
    "              'Author Use of Honorific', 'Author Name in All Caps',\n",
    "              ]]\n",
    "\n",
    "issue_columns = ['Language Type', 'Author Use of Honorific', \n",
    "                 'Author Initials', 'Institutions as Authors', \n",
    "                 'Author Name in All Caps',\n",
    "                 ]\n",
    "qual_df.fillna({'Language Type': 'Uncategorized'}, inplace=True)\n",
    "grouped = qual_df.groupby('Language Type', observed=False)[issue_columns].mean(numeric_only=True).reset_index()\n",
    "melted = grouped.melt(id_vars='Language Type', var_name='issue', value_name='prevalence')\n",
    "melted['prevalence'] = melted.prevalence.map(lambda x: x*100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x='issue', y='prevalence', hue='Language Type', data=melted, palette=['thistle','coral', 'skyblue', 'silver'],\n",
    "            hue_order=['Monolingual English', 'Monolingual Non-English', 'Multilingual', 'Uncategorized'])\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, size=8, fmt='%.1f')\n",
    "\n",
    "plt.xlabel('Issue')\n",
    "plt.ylabel('Prevalence')\n",
    "plt.xticks(rotation=20)\n",
    "ax.legend(title='Language Type', bbox_to_anchor=(0, 1), loc='upper left', frameon=False)\n",
    "\n",
    "plt.savefig(figure_dir / 'quality_lang_type.png', format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_groups = ['Monolingual English', 'Monolingual Non-English', 'Multilingual']\n",
    "\n",
    "for i in lang_groups:\n",
    "    temp = df.loc[df.lang_type == i]\n",
    "    num_rec = str(temp.shape[0])\n",
    "    num_pub = str(temp.publisher_name.nunique())\n",
    "    rec_pub = (temp.shape[0]/temp.publisher_name.nunique())\n",
    "    num_journ = str(temp.journal_title.nunique())\n",
    "    percent_share = ((temp.shape[0]/df.shape[0]) * 100)\n",
    "    print(f'{i} -- \\n')\n",
    "    print(f'Records: {num_rec}, Publishers: {num_pub}, Mean: {round(rec_pub,1)}, Journals: {num_journ}, Percent of Total: {round(percent_share,1)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.loc[df.lang_type.isna()]\n",
    "num_rec = temp.shape[0]\n",
    "num_pub = temp.publisher_name.nunique()\n",
    "rec_pub = temp.shape[0]/temp.publisher_name.nunique()\n",
    "num_journ = temp.journal_title.nunique()\n",
    "percent_share = ((temp.shape[0]/df.shape[0]) * 100)\n",
    "print(f'Uncategorized -- \\n')\n",
    "print(f'Records: {num_rec}, Publishers: {num_pub}, Mean: {round(rec_pub,1)}, Journals: {num_journ}, Percent of Total: {round(percent_share,1)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = ['Author Missing', 'Affiliation Missing', 'Abstract Missing',\n",
    "          'Article Language Missing','Article Title Missing']\n",
    "comp = df2.loc[(df2['Author Missing'] == 1) | (df2['Affiliation Missing'] == 1) |\n",
    "              (df2['Abstract Missing'] == 1) | (df2['Article Language Missing'] == 1) |\n",
    "              (df2['Article Title Missing'] == 1)]\n",
    "prev_comp = (comp.shape[0]/df2.shape[0]) * 100\n",
    "print(f'Prevalence of Completeness Issues: {prev_comp}\\n')\n",
    "\n",
    "for i in issues:\n",
    "    temp = df2.loc[df2[i] == 1]\n",
    "    prev = (temp.shape[0]/df2.shape[0]) * 100\n",
    "    print(f'Prevalence of {i} Completeness Issues: {round(prev,2)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues\n",
    "\n",
    "The first set is the prevalence within the entire sample, (# of Records with Issue)/(# of Records in the sample).\n",
    "\n",
    "The second set looks at each issue as (# of Records with issue)/(# of Records with data within the Field) e.g. (# of Multilingual Abstracts)/(# of Records that have abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = ['Author Use of Honorific', \n",
    "               'Institutions as Authors', 'Author Name in All Caps',\n",
    "               'Multilingual Abstract', 'Title Language Match',\n",
    "               'Author Initials']\n",
    "\n",
    "#Status and Language categories. \"Value disagrees with parameters of field\" Form. Excludes initials in author name\n",
    "status_lang = df2.loc[(df2['Author Use of Honorific'] == 1) |\n",
    "               (df2['Institutions as Authors'] == 1) | (df2['Author Name in All Caps'] == 1) |\n",
    "               (df2['Multilingual Abstract'] == 1) | (df2['Title Language Match'] == 1)]\n",
    "prev_status = (status_lang.shape[0]/df2.shape[0]) * 100\n",
    "print(f'Prevalence of Status and Language Issues: {prev_status}\\n')\n",
    "\n",
    "for i in issues:\n",
    "    temp = df2.loc[df2[i] == 1]\n",
    "    prev = (temp.shape[0]/df2.shape[0]) * 100\n",
    "    print(f'Prevalence of {i} Quality Issues: {round(prev,2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_dict = {'Multilingual Abstract': 'abstracts',\n",
    "              'Author Use of Honorific': 'authors',\n",
    "              'Institutions as Authors' : 'authors',\n",
    "              'Author Name in All Caps': 'authors',\n",
    "              'Title Language Mismatch': 'journal_lang',\n",
    "              'Author Initials' : 'authors',\n",
    "              'Affiliation Missing': 'authors'}\n",
    "\n",
    "for k,v in issue_dict.items():\n",
    "    temp = df2.loc[df2[k] == 1]\n",
    "    other = df.loc[df[v].notnull()]\n",
    "    prev = (temp.shape[0]/other.shape[0]) * 100\n",
    "    print(f'Prevalence of {k} Quality Issues: {round(prev,2)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author Sequence Seperation\n",
    "\n",
    "To get numbers about which specific Author sequence issue is occuring, All first Authors or No First authors, we'll run the function again, but we'll return specific information: `All First` or `No First`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_checker(authorList):\n",
    "    counter = 0 \n",
    "    try: \n",
    "        for author in authorList:\n",
    "            if author['sequence'] == 'first':\n",
    "                counter +=1\n",
    "            else:\n",
    "                continue\n",
    "        if counter == 0:\n",
    "            return 'No First' #no first author\n",
    "        elif len(authorList) > 1:\n",
    "            if counter > 1:\n",
    "                return 'All First' #multiple first authors\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0 #no issue\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_sequence'] = df.authors.map(lambda x: sequence_checker(x))\n",
    "df.author_sequence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['All First', 'No First']\n",
    "\n",
    "for o in options:\n",
    "    temp = df.loc[df.author_sequence == o]\n",
    "    prev_all = (temp.shape[0]/df.shape[0]) * 100\n",
    "    author_excl = df.loc[df.authors.notnull()]\n",
    "    prev_excl = (temp.shape[0]/author_excl.shape[0]) * 100\n",
    "    print(f'Prevalence (pop=entire sample) of {o} Sequence issue: {prev_all}\\n')\n",
    "    print(f'Prevalence (records with authors) of {o} Sequence issue: {prev_excl}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Prevalence\n",
    "\n",
    "Status, Language categories\n",
    "\n",
    "Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = ['Affiliation Missing', 'Institutions as Authors', 'Author Use of Honorific',\n",
    "          'Author Name in All Caps']\n",
    "\n",
    "status_df = df2.loc[(df2[status[0]] == 1) | (df2[status[1]] == 1) |\n",
    "                     (df2[status[2]] == 1) | (df2[status[3]] == 1)]\n",
    "prev_status = (status_df.shape[0]/df2.shape[0]) * 100\n",
    "print(f'Prevalence of Status Issues: {prev_status}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = ['Multilingual Abstract', 'Abstract Language Match', 'Article-Journal Language Mismatch',\n",
    "        'Title Language Mismatch']\n",
    "\n",
    "lang_df = df2.loc[(df2[lang[0]] == 1) | (df2[lang[1]] == 1) |\n",
    "                     (df2[lang[2]] == 1) | (df2[lang[3]] == 1)]\n",
    "prev_lang = (lang_df.shape[0]/df2.shape[0]) * 100\n",
    "print(f'Prevalence of Language Issues: {prev_lang}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = df.loc[df['lang_type'] == 'Multilingual']\n",
    "multi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_english(record):\n",
    "    try:\n",
    "        stated_abstract_langs = record['abstract_langs'] #list\n",
    "        stated_journal_lang = record['journal_lang'] # str\n",
    "        stated_article_lang = record['article_lang'] #str\n",
    "        detected_language_abstract = record['detected_lang_abstract'] #list\n",
    "        detected_language_title = record['detected_lang_title'] #str\n",
    "        lang_list = [\n",
    "                    stated_journal_lang,\n",
    "                    stated_article_lang,\n",
    "                    detected_language_title,\n",
    "                    ]\n",
    "        if stated_abstract_langs is not None:\n",
    "            lang_list.extend(stated_abstract_langs)\n",
    "        if detected_language_abstract is not None:\n",
    "            lang_list.extend(detected_language_abstract)\n",
    "        set_langs = set(lang_list)\n",
    "        set_langs = list(set_langs)\n",
    "        return set_langs\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "multi['set_langs'] = multi.apply(has_english, axis=1)\n",
    "exp_Langs = multi.explode('set_langs')\n",
    "exp_Langs.set_langs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
