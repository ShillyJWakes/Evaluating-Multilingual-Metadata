{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa28d027-7ae4-4458-b17b-552b46e3f161",
   "metadata": {},
   "source": [
    "***************************************************************************************\n",
    "Jupyter Notebooks from the Metadata for Everyone project\n",
    "\n",
    "Code:\n",
    "* Dennis Donathan II (https://orcid.org/0000-0001-8042-0539)\n",
    "\n",
    "Project team: \n",
    "* Juan Pablo Alperin (https://orcid.org/0000-0002-9344-7439)\n",
    "* Dennis Donathan II (https://orcid.org/0000-0001-8042-0539)\n",
    "* Mike Nason (https://orcid.org/0000-0001-5527-8489)\n",
    "* Julie Shi (https://orcid.org/0000-0003-1242-1112)\n",
    "* Marco Tullney (https://orcid.org/0000-0002-5111-2788)\n",
    "\n",
    "Last updated: xxx\n",
    "***************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efae076",
   "metadata": {},
   "source": [
    "# Language Detection\n",
    "\n",
    "In the previous notebook, we found that a significant number of records are missing a stated *language* within the record. Additionally, we found in our work in phase 1 of our project (see Shi, J., Nason, M., Tullney, M., & Alperin, J. P. (2023). Identifying Metadata Quality Issues Across Cultures. SocArXiv. https://doi.org/10.31235/osf.io/6fykh)) it is not uncommon for the stated language of the record to be inaccurate. This could be for a variety of reasons: lack of clarity as to what *language* is actually referring to (i.e. the language of the item, container, or the metadata record itself), perhaps some level of increased discoverability if the work is labeled with **en** (English).\n",
    "\n",
    "To examine these issues more closely, we will detect the languages used within the records, compare that against their stated languages, and see any patterns that emerge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a48e1-349d-497a-92c7-091dff8dd170",
   "metadata": {},
   "source": [
    "## Preparation \n",
    "First we will import several of the necessary packages, set up our directory, and import our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c388426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # data visualizations\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd #Creating dataframe and manipulating data\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from py3langid.langid import LanguageIdentifier, MODEL_FILE\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a4cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Directory\n",
    "data_dir = Path('../data')\n",
    "input_dir = data_dir / 'input'\n",
    "output_dir = data_dir / 'output'\n",
    "# Loading in dataset\n",
    "df = pd.read_parquet(output_dir / '03_labeled_data.parquet')\n",
    "#df = df_all.loc[df_all.abstracts.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce3209",
   "metadata": {},
   "source": [
    "## Detecting Languages\n",
    "We'll use `py3langid` as we did previously, with the same language list as before. While `py3langid` is optimized for python3 and is several times faster than the original, it is important to note that due to the nature of the language detection we will be doing, it may take a minute or two, but no longer than that. We will check each record across three fields, *abstract*, *title*, and *container-title*. These are the fields that have some of the most text, and thus can give us the most confident results. We'll set a probability threshold of `.95` to help insure that we are only saying a language is present when the model is very confident.\n",
    "\n",
    "### Matching\n",
    "After detecting the langauge used in the records, we will then see if the `detected_lang` matches the record's stated *language*. In doing this we will label the record with a `0` if the stated language matches detected language, `1` if the stated language **does not** match detected language), or `2` if the multiple detected languages, but one of the detected languages matches the stated language). \n",
    "\n",
    "### Language Type\n",
    "Finally, we will apply an additional code to each record: `0` if the detected language is English, `1` if the detected language is any single non-english language, `2` for multilingual records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867bce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = LanguageIdentifier.from_pickled_model(MODEL_FILE, norm_probs = True)\n",
    "lang_list = ['af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', \n",
    "             'bs', 'ca', 'cs', 'cy', 'da', 'de', 'dz', 'el', 'en', 'eo', \n",
    "             'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'ga', 'gl', 'gu', \n",
    "             'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'is', 'it', 'ja', 'jv', \n",
    "             'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lo', \n",
    "             'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'ne', \n",
    "             'nl', 'no', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'qu', 'ro', \n",
    "             'ru', 'rw', 'se', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', \n",
    "             'ta', 'te', 'th', 'tl', 'tr', 'ug', 'uk', 'ur', 'vi', 'vo', \n",
    "             'wa', 'xh', 'zh', 'zu']\n",
    "identifier.set_languages(langs=lang_list)\n",
    "# Check across multiple fields within each record for the languages present.\n",
    "def record_lang_checker(abstracts: List[str]) -> Optional[List[str | None]]:\n",
    "    #These fields have the most text which will provide the most accurate language detection\n",
    "    #fields = ['abstract', 'title', 'container-title']\n",
    "    #fields = ['abstract']\n",
    "    lang_list = []\n",
    "    #for col in fields:\n",
    "    try:\n",
    "        for abstract in abstracts:\n",
    "            tokenized = sent_tokenize(abstract)\n",
    "            for i in tokenized:\n",
    "                detect = identifier.classify(i.lower())\n",
    "                # Setting a .95 probability threshold for asserting the language is indeed in the record\n",
    "                if detect[1] > .95:\n",
    "                    lang_list.append(detect[0])\n",
    "                else:\n",
    "                    pass\n",
    "    except:\n",
    "        return None\n",
    "    #If no language is detected, return None\n",
    "    if len(lang_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        #Returning all of the detected languages for each record\n",
    "        return list(set(lang_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89bb9c8-a8cb-436f-aeb1-4e2917285370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['detected_lang_abstract'] = df.abstracts.map(lambda x: record_lang_checker(x))\n",
    "detected_languages = df.explode('detected_lang_abstract')\n",
    "#detected_languages.detected_lang.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d58df-40d9-47d9-b738-aeffed058ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:0.0f} different languages have been detected in the sample.\".format(detected_languages.detected_lang_abstract.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe0629-17ad-4e6b-bcef-4e16dbb7ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_languages['detected_lang_abstract'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00234ce2-8cd0-4c1a-b6bc-acdc6a84ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['detected_lang_abstract'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.journal_lang.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "189d852c-079f-409c-b5eb-c5e80e173a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_match(record):\n",
    "    try:\n",
    "        #Filtering out records with no stated language\n",
    "        if record['journal_lang'] is None:\n",
    "            return 3\n",
    "        else:\n",
    "            #checking if stated language matches detected language\n",
    "            if record['journal_lang'] in record['detected_lang_abstract']:\n",
    "                #Stated language is within the detected languages, but there are multiple languages\n",
    "                #present in the record\n",
    "                if len(record['detected_lang_abstract']) > 1:\n",
    "                    return 2\n",
    "                #Stated language matches detected language\n",
    "                else:\n",
    "                    return 0\n",
    "            #Stated and detected languages do not match\n",
    "            else:\n",
    "                return 1\n",
    "    except:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b90fa-7abb-4b6d-a78e-5c408d656eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang_match_abstract'] = df.apply(detection_match, axis=1)\n",
    "df.lang_match_abstract.value_counts()\n",
    "# 0.0 -> the language indicated matches the detected language\n",
    "# 1.0 -> there is only one language detected, and the language indicated does not match the detected language\n",
    "# 2.0 -> there are at least two languages detected, and the language indicated is one of the detected languages\n",
    "# 3.0 -> there is no indicated language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d170beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_lang_detector(article_title: list[str]) -> str | None:\n",
    "    \"\"\"Function to determine if the detected language of the title matches\n",
    "    the stated language of the journal within a given record.\n",
    "\n",
    "    Args:\n",
    "        record (pd.Series): A metadata record from the dataframe.\n",
    "\n",
    "    Returns:\n",
    "        int | None: Returns a binary encoding (0, 1) depending on the (non-)existence of an issue.\n",
    "        Returns None if the record is incomplete such that a determination cannot be made.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if article_title:\n",
    "            for i in article_title:\n",
    "                lang = identifier.classify(i)\n",
    "                if lang[1] > .99:\n",
    "                    return lang[0]\n",
    "                else:\n",
    "                    return None\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['detected_lang_title'] = df.article_title.map(lambda x: title_lang_detector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.detected_lang_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract_langs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ffbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_type(record):\n",
    "    stated_abstract_langs = record['abstract_langs'] #list\n",
    "    stated_journal_lang = record['journal_lang'] # str\n",
    "    stated_article_lang = record['article_lang'] #str\n",
    "    detected_language_abstract = record['detected_lang_abstract'] #list\n",
    "    detected_language_title = record['detected_lang_title'] #str\n",
    "    lang_list = [\n",
    "                stated_journal_lang,\n",
    "                stated_article_lang,\n",
    "                detected_language_title,\n",
    "                ]\n",
    "    if stated_abstract_langs is not None:\n",
    "        lang_list.extend(stated_abstract_langs)\n",
    "    if detected_language_abstract is not None:\n",
    "        lang_list.extend(detected_language_abstract)\n",
    "    set_langs = set(lang_list)\n",
    "    set_langs = list(set_langs)\n",
    "    if len(set_langs) == 1:\n",
    "        if set_langs[0] is None:\n",
    "            return None\n",
    "        else:\n",
    "            if set_langs[0] == 'en':\n",
    "                return 'Monolingual English'\n",
    "            else:\n",
    "                return 'Monolingual Non-English'\n",
    "    if len(set_langs) == 2:\n",
    "        filtered_lang = [lang for lang in set_langs if lang is not None]\n",
    "        if len(filtered_lang) == 1:\n",
    "            if filtered_lang[0] == 'en':\n",
    "                return 'Monolingual English'\n",
    "            else:\n",
    "                return 'Monolingual Non-English'\n",
    "        else:\n",
    "            return 'Multilingual'\n",
    "    if len(set_langs) > 2:\n",
    "        return 'Multilingual'\n",
    "    print(set_langs)\n",
    "    \n",
    "df['lang_type'] = df.apply(lang_type, axis=1)\n",
    "df.lang_type.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e79ea8-c575-4c5e-8327-eec54d7dee5f",
   "metadata": {},
   "source": [
    "## Analyses by language type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c2161-bfb9-477a-bb81-9630892fc72d",
   "metadata": {},
   "source": [
    "⚠️ So this is where we should try to differentiate RQ1 results by language type. If you have the time, could you try to do \"language absent\" and \"author initials\"? I could then try to do a few other important ones. ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba21fe",
   "metadata": {},
   "source": [
    "## Differences in Errors Between Language Types\n",
    "After detecting the languages and coding the records, we can see that there are a large number of records in which the `detected_lang` does not match the stated language. One possible explanation is the high number of records that simply do not have a stated language. We will explore this below.\n",
    "\n",
    "Additionally, we can see that English is the predominant language of the dataset. Next, we'll take a look at errors per record in regards to the different language types: English-monolingual, Non-English-monolingual, and Multilingual.\n",
    "\n",
    "First, we'll take a look at the number of errors per language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_langs = detected_languages.groupby('detected_lang_abstract')\n",
    "group_total_errors = grouped_langs.agg({'Total Errors': 'sum', 'doi': 'count'}).sort_values(by='doi', ascending=False)\n",
    "group_total_errors[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "top_20 = group_total_errors.sort_values(by='Total Errors', ascending=False)[:20]\n",
    "t20plt = sns.barplot(data=top_20, x=top_20.index, y='Total Errors')\n",
    "t20plt.set_xticklabels(t20plt.get_xticklabels(), rotation=40, ha='right', fontsize=10)\n",
    "t20plt.set_title('Total Errors by Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75487b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll remove English, to better visualize other languages\n",
    "no_en = group_total_errors.drop('en')\n",
    "top_20 = no_en.sort_values(by='Total Errors', ascending=False)[:20]\n",
    "t20plt = sns.barplot(data=top_20, x=top_20.index, y='Total Errors')\n",
    "t20plt.set_xticklabels(t20plt.get_xticklabels(), rotation=40, ha='right', fontsize=10)\n",
    "t20plt.set_title('Total Errors by Language (excl. English)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll change from total errors, to the mean number of errors by language\n",
    "group_avg_errors = grouped_langs.agg({'Total Errors': 'mean', 'doi': 'count'}).sort_values(by='Total Errors', ascending=False)\n",
    "group_avg_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531973b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll remove the languages with only a couple of records\n",
    "filtered = group_avg_errors.loc[group_avg_errors.doi > 5].sort_values(by='Total Errors', ascending=False)\n",
    "top_20 = filtered[:20]\n",
    "t20plt = sns.barplot(data=top_20, x=top_20.index, y='Total Errors')\n",
    "t20plt.set_xticklabels(t20plt.get_xticklabels(), rotation=40, ha='right', fontsize=10)\n",
    "t20plt.set_title('Errors per Record by Language')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44174aa5",
   "metadata": {},
   "source": [
    "### Individual Languages\n",
    "We see that, as mentioned, English is by far the most represented language in the dataset, and, consequently, has the most errors. Once removing english, we see that German (de), French (fr), Spanish (es), Portugese (pt), and Malay (ms) are the next top 5 in total errors, but that tends to be a reflection of the quantity of  in the dataset.\n",
    "\n",
    "However, when we look at the average (arithmetic mean) of the errors per language, we do see that there are a number of languages from the top 20 of total errors there:\n",
    "\n",
    "Chinese (zh), Russian (ru), Ukranian (uk), Bulgarian (bg), Japanese (ja), Arabic (ar).\n",
    "\n",
    "Now, we'll take a look at the differences between language types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ed8a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = df.loc[df.lang_type == 'Multilingual']\n",
    "non_english = df.loc[df.lang_type == 'Monolingual Non-English']\n",
    "english = df.loc[df.lang_type == 'Monolingual English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441201f7-5c1c-4827-ac5c-3b69c190bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi[\"DOI\"].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6292767",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_error_rate = multi['Total Errors'].sum()/len(multi)\n",
    "eng_error_rate = english['Total Errors'].sum()/len(english)\n",
    "non_eng_error_rate = non_english['Total Errors'].sum()/len(non_english)\n",
    "\n",
    "print(\"{:0.2f} errors per english, monolingual record\".format(eng_error_rate))\n",
    "print(\"{:0.2f} errors per non-english, monolingual record\".format(non_eng_error_rate))\n",
    "print(\"{:0.2f} errors per multilingual record\".format(multi_error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767700b",
   "metadata": {},
   "source": [
    "To visualize this data, we'll look at the error rates for each of these language types and break them up by their publisher bin.\n",
    "\n",
    "Then We'll take a look at any differences between the languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multilingual Records\n",
    "#mlt = sns.catplot(data=multi,x='publisher_bin', y='total_errors', kind='bar', height=4, aspect=.8, order=['XS', 'S', 'M', 'L', 'XL'], errorbar=None)\n",
    "#mlt.set_axis_labels('', 'Error per Record')\n",
    "#mlt.fig.subplots_adjust(top=0.9)\n",
    "#mlt.fig.suptitle('Errors per Record by Publisher Size, Multilingual Records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1edeecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#English Monolingual Records\n",
    "#en_only = sns.catplot(data=english, x='publisher_bin', y='total_errors', kind='bar', height=4, aspect=.8, order=['XS', 'S', 'M', 'L', 'XL'], errorbar=None)\n",
    "#en_only.set_axis_labels('', 'Error per Record')\n",
    "#en_only.fig.subplots_adjust(top=0.9)\n",
    "#en_only.fig.suptitle('Errors per Record by Publisher Size, English Only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff191edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-English Monolingual Records\n",
    "#non_en_plt = sns.catplot(data=non_english, x='publisher_bin', y='total_errors', kind='bar', height=4, aspect=.8, order=['XS', 'S', 'M', 'L', 'XL'], errorbar=None)\n",
    "#non_en_plt.set_axis_labels('', 'Error per Record')\n",
    "#non_en_plt.fig.subplots_adjust(top=0.9)\n",
    "#non_en_plt.fig.suptitle('Errors per Record by Publisher Size, Monolingual Records (non-English)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e5377",
   "metadata": {},
   "source": [
    "### Differences in Language Types\n",
    "We can see that the publisher bins generally change between groups in a similar fashion. The error rate for all seems to be highest in non-English monolingual records, and at its lowest in English monolingual records.\n",
    "\n",
    "Consistent throughout all groups the XS publisher bin has the highest error rate.\n",
    "\n",
    "Finally, we'll take a look to see any differences in the presence of a stated language between the language types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_no_lang = (multi.journal_lang.isna().sum()/len(multi)) *100\n",
    "eng_no_lang = (english.journal_lang.isna().sum()/len(english)) *100\n",
    "non_eng_no_lang = (non_english.journal_lang.isna().sum()/len(non_english)) * 100\n",
    "\n",
    "print(\"{:0.2f}% english, monolingual records with no stated language\".format(eng_no_lang))\n",
    "print(\"{:0.2f}% non_english, monolingual records with no stated language\".format(non_eng_no_lang))\n",
    "print(\"{:0.2f}% multilingual records with no stated language\".format(multi_no_lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccdccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_stated(lang):\n",
    "    try:\n",
    "        if lang == 'en':\n",
    "            return 1\n",
    "        elif lang in lang_list:\n",
    "            return 0\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "find_stated = non_english.journal_lang.map(lambda x: en_stated(x))\n",
    "enStated = find_stated.sum()\n",
    "nonenStated = len(find_stated.loc[find_stated == 0])\n",
    "non_eng_no_lang = non_english.journal_lang.isna().sum()\n",
    "labels = ['English', 'Non-English', 'No Language']\n",
    "data = [enStated, nonenStated, non_eng_no_lang]\n",
    "colors = ['palegreen','skyblue', 'pink']\n",
    "fig = plt.figure(figsize = (10,7))\n",
    "plt.pie(data, labels = labels, autopct='%.1f%%', colors=colors)\n",
    "plt.title('Breakdown of Stated Languages for Non-English, Monolingual Records', fontsize=16)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df75ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_stated = multi.journal_lang.map(lambda x: en_stated(x))\n",
    "enStated = find_stated.sum()\n",
    "nonenStated = len(find_stated.loc[find_stated == 0])\n",
    "multi_no_lang = multi.journal_lang.isna().sum()\n",
    "labels = ['English', 'Non-English', 'No Language']\n",
    "data = [enStated, nonenStated, multi_no_lang]\n",
    "colors = ['palegreen','skyblue', 'pink']\n",
    "fig = plt.figure(figsize = (10,7))\n",
    "plt.pie(data, labels = labels, autopct='%.1f%%', colors=colors)\n",
    "plt.title('Breakdown of Stated Languages for Multilingual Records', fontsize=16)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking to see how many multilingual records use english within their records\n",
    "def has_english(record):\n",
    "    try:\n",
    "        stated_abstract_langs = record['abstract_langs'] #list\n",
    "        stated_journal_lang = record['journal_lang'] # str\n",
    "        stated_article_lang = record['article_lang'] #str\n",
    "        detected_language_abstract = record['detected_lang_abstract'] #list\n",
    "        detected_language_title = record['detected_lang_title'] #str\n",
    "        lang_list = [\n",
    "                    stated_journal_lang,\n",
    "                    stated_article_lang,\n",
    "                    detected_language_title,\n",
    "                    ]\n",
    "        if stated_abstract_langs is not None:\n",
    "            lang_list.extend(stated_abstract_langs)\n",
    "        if detected_language_abstract is not None:\n",
    "            lang_list.extend(detected_language_abstract)\n",
    "        set_langs = set(lang_list)\n",
    "        set_langs = list(set_langs)\n",
    "        if 'en' in set_langs:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "eng_multi = multi.apply(has_english, axis=1)\n",
    "eng_having_rate = (eng_multi.sum()/len(multi)) *100\n",
    "print(\"{:0.2f}% of multilingual records have English as one of their languages\".format(eng_having_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d52a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(output_dir / '04_language_detection.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
